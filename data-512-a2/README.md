# data512-a2

### Goal
Google data scientists used the Wikipedia Talk corpus to train machine learning models as part of a project called Conversation AI. The models have been used in a variety of software products and made freely accessible to anyone through the Perspective API. The motivation for this analysis is to identify any source of bias in the Wikipedia Talk corpus and discuss the implications of these biases.

### Resources and Documentation
Data: https://figshare.com/projects/Wikipedia_Talk/16731
Detox wiki page: https://meta.wikimedia.org/wiki/Research:Detox
Perspective API Documentation: https://github.com/conversationai/perspectiveapi/blob/master/2-api/methods.md

### Dataset
The corpus you will use is called the Wikipedia Talk corpus, and it consists of three datasets. Each dataset contains thousands of online discussion posts made by Wikipedia editors who were discussing how to write and edit Wikipedia articles. Crowdworkers labelled these posts for three kinds of hostile speech: “toxicity”, “aggression”, and “personal attacks”. Many posts in each dataset were labelled by multiple crowdworkers for each type of hostile speech, to improve accuracy.
